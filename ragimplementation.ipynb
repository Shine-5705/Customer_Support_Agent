{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import uuid\n",
        "import datetime\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import faiss\n",
        "import pickle\n",
        "from ollama import Client\n",
        "\n",
        "client = Client(host=\"http://localhost:11434\")\n",
        "embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "\n",
        "# Load vector DB + metadata\n",
        "index = faiss.read_index(\"vector.index\")\n",
        "with open(\"metadata.pkl\", \"rb\") as f:\n",
        "    metadata = pickle.load(f)\n",
        "\n",
        "# Chat state\n",
        "chat_history = []\n",
        "MAX_TURNS = 10\n",
        "session_id = str(uuid.uuid4())[:8]\n",
        "chat_log_file = f\"chat_log_{session_id}.json\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def retrieve_context(query, k=5):\n",
        "    vec = embedding_model.encode([query])\n",
        "    distances, indices = index.search(vec, k)\n",
        "    return [metadata[i] for i in indices[0]]\n",
        "\n",
        "def build_prompt(query, context):\n",
        "    context_text = \"\\n\\n\".join(\n",
        "        f\"Title: {doc['title']}\\nURL: {doc['url']}\\n\\n{doc.get('cleaned_content', '')[:1000]}\"\n",
        "        for doc in context\n",
        "    )\n",
        "    return context_text\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def save_chat_log():\n",
        "    if not chat_history:\n",
        "        return\n",
        "    with open(chat_log_file, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(chat_history, f, indent=2)\n",
        "\n",
        "def reset_chat():\n",
        "    global chat_history, session_id, chat_log_file\n",
        "    chat_history = []\n",
        "    session_id = str(uuid.uuid4())[:8]\n",
        "    chat_log_file = f\"chat_log_{session_id}.json\"\n",
        "    print(f\"ðŸ”„ New session started: {session_id}\")\n",
        "\n",
        "def chat_with_mistral(query):\n",
        "    global chat_history\n",
        "\n",
        "    if query.strip().lower() == \"clear\":\n",
        "        reset_chat()\n",
        "        return \"ðŸ§¼ Chat memory cleared. New session started.\"\n",
        "\n",
        "    now = datetime.datetime.now().isoformat()\n",
        "\n",
        "    # Retrieve documents\n",
        "    docs = retrieve_context(query)\n",
        "    context = build_prompt(query, docs)\n",
        "\n",
        "    # Memory history\n",
        "    memory = \"\\n\".join(\n",
        "        f\"[{ts}] User: {q}\\n[{ts2}] Agent: {a}\"\n",
        "        for (q, a, ts, ts2) in chat_history[-MAX_TURNS:]\n",
        "    )\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "You are a helpful research assistant for DRDO analysts.\n",
        "\n",
        "Previous conversation:\n",
        "{memory}\n",
        "\n",
        "Relevant context:\n",
        "{context}\n",
        "\n",
        "[{now}] User: {query}\n",
        "\n",
        "Answer:\"\"\"\n",
        "\n",
        "    response = client.chat(\n",
        "        model=\"mistral\",\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
        "    )\n",
        "\n",
        "    answer = response[\"message\"][\"content\"]\n",
        "    chat_history.append((query, answer, now, datetime.datetime.now().isoformat()))\n",
        "    save_chat_log()\n",
        "    return answer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ¤– DRDO Agent [Session a615718f] is ready. Type 'exit' or 'clear'.\n"
          ]
        }
      ],
      "source": [
        "print(f\"ðŸ¤– DRDO Agent [Session {session_id}] is ready. Type 'exit' or 'clear'.\")\n",
        "\n",
        "while True:\n",
        "    user_input = input(\"\\nYou: \")\n",
        "    if user_input.lower() in [\"exit\", \"quit\"]:\n",
        "        print(\"ðŸ‘‹ Ending session.\")\n",
        "        break\n",
        "    reply = chat_with_mistral(user_input)\n",
        "    print(\"\\nAgent:\", reply)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
